{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c0de73-9ceb-4839-8b2c-dd78f9c38777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "### LLM\n",
    "local_llm = \"deepseek-r1:latest\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model = local_llm, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f967c952-55fd-49f0-b220-73e277d321a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from dataclasses import dataclass, field\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryState:\n",
    "    research_topic: str = field(default=None) # Report topic     \n",
    "    search_query: str = field(default=None) # Search query\n",
    "    web_research_results: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    sources_gathered: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    research_loop_count: int = field(default=0) # Research loop count\n",
    "    running_summary: str = field(default=None) # Final report\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryStateInput:\n",
    "    research_topic: str = field(default=None) # Report topic     \n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryStateOutput:\n",
    "    running_summary: str = field(default=None) # Final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d09f8bc-3753-4c94-b1a5-349cb2aff764",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_writer_instructions=\"\"\"Your goal is to generate a targeted web search query.\n",
    "\n",
    "<CONTEXT>\n",
    "Current date: {current_date}\n",
    "Please ensure your queries account for the most current information available as of this date.\n",
    "</CONTEXT>\n",
    "\n",
    "<TOPIC>\n",
    "{research_topic}\n",
    "</TOPIC>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with ALL three of these exact keys:\n",
    "   - \"query\": The actual search query string\n",
    "   - \"rationale\": Brief explanation of why this query is relevant\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"query\": \"machine learning transformer architecture explained\",\n",
    "    \"rationale\": \"Understanding the fundamental structure of transformer models\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your response in JSON format:\"\"\"\n",
    "\n",
    "summarizer_instructions=\"\"\"\n",
    "<GOAL>\n",
    "Generate a high-quality summary of the provided context.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "When creating a NEW summary:\n",
    "1. Highlight the most relevant information related to the user topic from the search results\n",
    "2. Ensure a coherent flow of information\n",
    "\n",
    "When EXTENDING an existing summary:                                                                                                                 \n",
    "1. Read the existing summary and new search results carefully.                                                    \n",
    "2. Compare the new information with the existing summary.                                                         \n",
    "3. For each piece of new information:                                                                             \n",
    "    a. If it's related to existing points, integrate it into the relevant paragraph.                               \n",
    "    b. If it's entirely new but relevant, add a new paragraph with a smooth transition.                            \n",
    "    c. If it's not relevant to the user topic, skip it.                                                            \n",
    "4. Ensure all additions are relevant to the user's topic.                                                         \n",
    "5. Verify that your final output differs from the input summary.                                                                                                                                                            \n",
    "< /REQUIREMENTS >\n",
    "\n",
    "< FORMATTING >\n",
    "- Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.  \n",
    "< /FORMATTING >\n",
    "\n",
    "<Task>\n",
    "Think carefully about the provided Context first. Then generate a summary of the context to address the User Input.\n",
    "</Task>\n",
    "\"\"\"\n",
    "\n",
    "reflection_instructions = \"\"\"You are an expert research assistant analyzing a summary about {research_topic}.\n",
    "\n",
    "<GOAL>\n",
    "1. Identify knowledge gaps or areas that need deeper exploration\n",
    "2. Generate a follow-up question that would help expand your understanding\n",
    "3. Focus on technical details, implementation specifics, or emerging trends that weren't fully covered\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "Ensure the follow-up question is self-contained and includes necessary context for web search.\n",
    "</REQUIREMENTS>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with these exact keys:\n",
    "- knowledge_gap: Describe what information is missing or needs clarification\n",
    "- follow_up_query: Write a specific question to address this gap\n",
    "</FORMAT>\n",
    "\n",
    "<Task>\n",
    "Reflect carefully on the Summary to identify knowledge gaps and produce a follow-up query. Then, produce your output following this JSON format:\n",
    "{{\n",
    "    \"knowledge_gap\": \"The summary lacks information about performance metrics and benchmarks\",\n",
    "    \"follow_up_query\": \"What are typical performance benchmarks and metrics used to evaluate [specific technology]?\"\n",
    "}}\n",
    "</Task>\n",
    "\n",
    "Provide your analysis in JSON format:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de6edbe5-7b90-4764-9c31-105e1c4f8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(state: SummaryState):\n",
    "\n",
    "    formatted_prompt = query_writer_instructions.format(\n",
    "        research_topic=state.research_topic\n",
    "    )\n",
    "\n",
    "    # Generate a query\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    result = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=f\"Generate a query for web search:\")]\n",
    "    )\n",
    "    \n",
    "    # Get the content\n",
    "    content = result.content\n",
    "\n",
    "    # Parse the JSON response and get the query\n",
    "    try:\n",
    "        query = json.loads(content)\n",
    "        search_query = query['query']\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        # If parsing fails or the key is not found, use a fallback query\n",
    "        if configurable.strip_thinking_tokens:\n",
    "            content = strip_thinking_tokens(content)\n",
    "        search_query = content\n",
    "    return {\"search_query\": search_query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b3091ab-db7e-468e-9306-7c82dcff9195",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RunnableConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mweb_research\u001b[39m(state: SummaryState, config: \u001b[43mRunnableConfig\u001b[49m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"LangGraph node that performs web research using the generated search query.\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[33;03m    Executes a web search using the configured search API (tavily, perplexity, \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[33;03m        Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Configure\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'RunnableConfig' is not defined"
     ]
    }
   ],
   "source": [
    "def web_research(state: SummaryState):\n",
    "    \"\"\"LangGraph node that performs web research using the generated search query.\n",
    "    \n",
    "    Executes a web search using the configured search API (tavily, perplexity, \n",
    "    duckduckgo, or searxng) and formats the results for further processing.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the search query and research loop count\n",
    "        config: Configuration for the runnable, including search API settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
    "    \"\"\"\n",
    "    \n",
    "    search_results = perplexity_search(state.search_query, state.research_loop_count)\n",
    "    search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, fetch_full_page=configurable.fetch_full_page)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3fecf6-9a3e-4322-9d6e-220fff3e66dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
